NB: NON STUDIARE DA QUA, SOLO RIASSUNTO.
NB2: pacchetto sarà utilizzato come sinonimo dell'entità da inviare di quel livello (frame, datagramma ecc)
• Capitolo 1: introduzione
Internet è composta di sistemi periferici (end systems) connessi tra loro mediante collegamenti (wireless e non).
Internet è anche l'insieme di servizi che fornisce alle applicazioni, come navigare, inviare messaggi o IoT.


Essendoci tante sottoreti connessi tra loro => rete di reti.


Per potersi scambiare messaggi due sistemi hanno bisogno di usare un protocollo.
Protocollo: definisce formato e ordine dei messaggi inviati e ricevuti, e azioni da compiere in base ai messaggi ricevuti o inviati.


Ai bordi di internet troviamo degli host: client e server, i quali accedono a internet mediante collegamenti.


I due sistemi più diffusi per accedere a internet: dsl (linea telefonica) e via cavo (canale tv).
Si può creare una rete di casa collegando al modem un router e un access point.


Una rete wireless può essere di due tipi: Lan (rete di casa vista prima) o a ampia area.


Come fa una host a mandare un messaggio? Lo divide in piccole parti dette pacchetti e li trasmette sulla rete.
Se lunghezza pacchetti L (bits) e velocità di trasmissione R (bits al secondo) allora il tempo di trasmissione
sarà L/R (secondi).


Se il collegamento è guidato allora i bit viaggiano in un collegamento solido propagandosi dal mittente al destinatario in un cavo, es cavo coassiale e fibra ottica.
Se il collegamento è non guidato allora viaggia liberamente, es radio.


Invece nel nucleo di internet vi è una maglia di routers interconnessi.
Perché un pacchetto arrivi al destinatario deve prima percorrere un percorso, venendo trasmetto tra diversi router.


Un router prima di inviare un pacchetto aspetta di ricevere tutti i suoi bit prima di inviarlo nel collegamento di uscita.
Se mittente e destinatario hanno un solo router in messo ci vogliono 2L/R secondi perché arrivi il pacchetto (L/R tutto al router e L/R tutto al destinatario).


Se il collegamento in uscita dovesse essere più lento di quello in ingresso arriverebbero più pacchetti di quanti se ne possono inviare => CODA DI PACCHETTI nel router, in attesa di essere inviati.
E se coda dovesse riempirsi? Nuovi pacchetti persi, PERDITA DI PACCHETTI.


Quali sono i due compiti principali di un router?
 - routing: determinare il percorso migliore per il pacchetto per arrivare al destinatario (algoritmi di routing).
 - forwarding: spostare pacchetto verso il prossimo router.


Un tipo di circuito alternativo è il circuit switching, dove ad ogni connessione tra sorgente e destinazione vengono allocate una parte delle risorse intermedie.
Essendo dedicate non vanno condivise con altre connessioni => massima potenza.
Se la connessione avesse tempi morti le risorse condivise iniziano ad oziare.


Essendo internet una rete di reti come vengono collegate queste reti?
Ogni rete si collega mediante access isp (sono gli internet service providers).
Ogni isp ha una sua maglia di router. Se due sistemi appartengono a due isp diversi, i pacchetti passeranno
tra i router delle due isp mediante ixp (internet exchange point).


Quando un pacchetto arriva ad un router ha 4 tipi di possibili ritardi:
 - elaborazione: tempo che il router processi il pachetto (controllo checksum, capire destinatario)
 - in coda: tempo che il pacchetto pasa in coda, molto situazionale.
 - trasmissione: L/R
 - di propagazione: tempo che i bit si propaghino nel collegamento ad arrivino a destinazione.
Ultimi due molto diversi.


Dati L lunghezza di un pacchetto, R larghezza di banda e a tasso media di arrivo dei pacchetti (pacchetti al sec).
se La/R è circa zero il ritardo di accodamento sarà basso.
se tende a 1 il ritardo di accodamento sarà alto.
se > 1 arriva più pacchetti di quanti se possono essere elaborati, packet loss sicuro.


Se un pacchetto passa tra n collegamenti, banda di un collegamento è R allora il throughput sarà Rm, dove m è il collegamento con la banda più bassa.


I servizi e protocolli internet vengono divisi in livelli, ogni livello usa servizi di quello inferiore.
I capitoli che andremo a studiare seguiranno questa suddivisione di livelli dal'alto verso il basso.


• Capitolo 2: Livello Applicativo, a questo livello si lavora su messaggi
Questo livello nasce dalla necessità di creare programmi che possano comunicare tra loro mediante internet, senza doverci preoccupare dei livelli inferiori (es socket).


Due architetture principali per le applicazioni sono:
 - client-server
 - peer-to-peer
NB: in generale client è colui che inizia la connessione, server è colui che aspetta di essere contattato.
In alcuni casi un host è sia client che server (es server email).


Come identifico un processo in un host? indirizzo ip host + numero porta associata a quel processo.


Un'occhiata veloce al livello di trasporto:
Quali servizi di trasporto (livello inferiore) possono servire ad un'applicazione:
 - integrità dei dati.
 - temporizzazione (ritardo basso).
 - throughtput (banda minima per funzionare).
 - sicurezza


Dal primo punto nascono i due protocolli di trasporto principali: TCP e UDP.


HTTP: protocollo per navigare sul web!
un web client (browser) richiede pagine ad un web server mediante protocollo http.
Di solito vengono richieste prima oggetti html, se questi referenziano degli oggetti allora vengono richiesti questi ultimi.
Non posso perdere parti di una pagine => viene utilizzato tcp (quindi ho anche handshake, congestione ecc).


Due tipi di http:
 - non persistente (fatta una richiesta e ricevuta la connessione viene subito chiusa)
 - persistente (possono essere soddisfatte più richieste sulla stessa connessione).
RTT (round trip time): tempo di un pacchetto per arrivare da client al server e tornare indietro al client.


Normalmente http è stateless, se vogliamo che il server memorizzi informazioni sui client servono i cookies.


Ma se più client richiedono le stesse pagine? con un proxy server possiamo fare web caching utilizzando il get condizionale.


FTP: protocollo invio di file
Sempre mediante tcp (non posso ricevere un file a cui mancano delle parti).
Il client contatta il server e creano una connessione di controllo.
Quando il client vuole ricevere o caricare un file viene aperta una seconda connessione detta connessione dei data.
Inviato il file il server chiude la connessione di data e la riapre se serve.
Connessione out of band (dati e comandi separati).


SMTP: protocollo per invio delle mail
Due componenti: user agents (utenti che scrivono e leggono mail) e mail servers (che memorizzano le mail nei mail box).
SMTP viene usato per inviare mail tra due componenti, usa tcp.
passi: handshake, invio email e chiusura connessione (connessioni persistenti).
A differenza di http che viene usato per ottenere dati (protocollo pull) smtp viene usato per inviare (protocollo push).


Se smtp è push, come fa uno user agent a richiedere le mail ricevute al suo mail server?
Usa degli algoritmi di pull per la posta, ovvero:
 - POP3, download-delete o download-keep, è stateless e molto semplice.
 - IMAP più complesso, mail vengono tenute sul server e possono essere organizzate in cartelle.


DNS: protocollo per assegnare nomi a indirizzi ip
Normalmente un utente che non naviga su internet non può memorizzare gli indirizzi ip dei server, per cui si associano dei nomi ai server.


Come mappiamo i nomi con i rispettivi indirizzi ip? Usiamo il dns, che è sia un database distribuito sia un protocollo a livello applicativo.


I suoi servizi sono: traduzione da nome host a indirizzo ip, alias per host e inidirizzi mail e distribuzione del carico di lavoro.


Quando da browser scriviamo www.google.com prima viene inviata la richiesta prima al server dns locale (estraneo alla gerarchia, fa da caching), se non trova l'indirizzo ip il dns locale chiede al root dns un indirizzo per un server tld (top-level domain) che possa tradurre indirizzi .com, a questo server chiede l'indirizzo ip per un server autoritativo per tradurre google.com. Ricevuto l'indirizzo ip il server locale lo salva nella sua cache e inoltre l'indirizzo al browser.
Ovviamente i server possono cambiare indirizzo, quindi ad ogni indirizzo ip il server locale assegna un tempo di scadenza, detto ttl.


I server dns hanno dei record detti resource record, RR, dove mappano (nome host, valore, tipo, ttl).
Il tipo indica se abbiamo un host e un indirizzo ip (server autoritativi) o se abbiamo un host e un altro host (a cui inoltrare la query, server root e tld).


Fino a questo momento tutti i protocolli si basavano sull'architettura client-server, ora andiamo a vedere l'architettura peer-to-peer.
Inquesta architettura i client (qua detti peer) comnicano direttamente tra di loro, quindi non esiste più un server sempre acceso con indirizzo ip fisso, inoltre i peer si spengono e cambiano indirizzo ip.
Essendo che i peer scaricano e condividono i file tra di loro, un server impiega meno tempo a condividere un file a n peers rispetto a n client in un'architettura cleint-server.


BitTorrent: Un protocollo peer-to-peer per condividere file
File viene diviso in piccole parti dette chunks, un torrent è un gruppo di peers che si connette per condividere un file. il Tracker è il server che memorizza i peer partecipanti al torrent.
Quando un peer si connette al torrent chiede al tracker la lista dei peer e inizia a chiedere chunks e condividere chunks con questi ultimi.
All'inizio non possiderà nessun chunk ma man mano che ne ottiene può richiederne e condividerne fino ad avere il file intero.
Per scaricare i chunks si chiede ai peer la lista di quali chunks possiedono e si richiedono a partire dai più rari (meno presenti nelle liste).
Per inviare i chunks che si possiedono si usa la tecnica del tit-for-tat: si inviano i chunks ai 4 peers che stanno condividendo più velocemente i chunks richiesti.
Inoltre ogni 30 secondi si sceglie casualmente un peer e si inizia a condividere i chunks con lui, il quale potrebbe iniziare a condividere i suoi chunks e entrare nei 4 che condividono più velocemente.


Socket: interfaccia tra un processo e il livello applicativo.
Mediante socket due processi che si trovano in macchine diverse (es client e server) possono comunicare tra di loro senza doversi preoccupare dei livelli inferiori.
Esistono due tipi: socket tcp e socket udp (primo reliable secondo no, primo lavora con byte il secondo con datagrammi).


• Capitolo 3: Livello Di Trasporto, a questo livello si lavora su segmenti
Servizio fondamentale: creare un canale logico di comunicazione tra applicazioni su host diversi.


Differenza tra livello di trasporto e di reti: reti connette due host (pc con router, router con router), trasporto connette processi di sistemi periferici (anche molto distanti).


Dato un messaggio esso viene diviso in segmenti, inviati al livello di rete.


Questo canale può essere:
 - affidabile, consegna di segmenti ordinata: TCP
 - non affidabile, ordine di consegna casuale: UDP.


Concetto fondamentale: multiplexing/demultiplexing
Multiplexing: prendere frammenti di dati da diverse socket sull'host di origine e incapsulare ognuno con instestazion a livello di trasporto, creando dei segmenti, e passarli al livello di rete.


Demultiplexing: Lato ricevente, il livello di trasporto esamina i segmenti ricevuti per dirigere i segmenti verso la giusta socket.


Perché il meccanismo funzioni bisogna aggiungere ai segmenti la porta di destinazione e di origine.
NB: indirizzi ip si trovano nei datagrammi ip (livello rete).


Se demultiplexing NON orientato alla connessione:
 => segmenti con stessa porta di destinazione ma diversi ip/porta sorgenti vengono mandati alla stessa socket.
 => socket udp identificati da: destinazione ip, destinazione porta.


Se demultiplexing orientato alla connessione:
 => i socket tcp vengono identificati da: (sorgente ip, sorgente porta, destinazione ip, destinazione porta)
 => se porta o ip sorgente diversi vengono mandati a socket diversi.


UDP: primo protocollo a livello di trasporto
Protocollo ridotto all'osso. Invia i segmenti senza preoccuparsi che arrivino o che arrivino in ordine.
Modello best-effort: segmenti arriveranno il più velocemente possibile al destinatario.
Senza connessione: non avviene handshaking tra mittente e destinatario.
Ottimo per streaming.
Header minimale: servono porta dest/sorg, lunghezza del segmento e il checksum.


Checksum:
obbiettivo => controllare se vi sono degli errori nel segmento ricevuto.
Come funziona:
 - Sorgente divide il segmento (incluso header) in parole di 16 bit.
 - somma tutte le parole di bit e ne fa il complemento a uno.
 - inserisce il valore ottenuto nel checksum.
 - Destinatario fa la stessa cosa e controllare se i valori del checksum coincidono.
Se non coincidono: abbiamo trovato un errore. Se coincidono non possiamo essere sicuri ma è un buon segno.


Prima di introdurre TCP dobbiamo parlare del trasferimento dati sicuro:
I processi a livello applicativo si aspettano che il livello di trasporto fornisca un canale di trasporto sicuro per i dati (arrivino a destinazione, in ordine e senza errori come bit invertiti).
Purtroppo il livello inferiore (di rete) non è affidabile.
Andiamo con ordine a creare dei meccanismi:


rdt 1.0: supponiamo il canale sicuro, mittente invia e ricevente riceve sempre, in ordine e pacchetti corretti.


rdt 2.0: ora il canale può invertire i bit, ma i pacchetti arriveranno e in ordine.
Come fare? Introduciamo i pacchetti ack e nack. ora il ricevente può confermare o chiedere di reinviare un pacchetto.
Meccanismo stop and wait: mittente invia un pacchetto e attende finché non riceve una risposta.


rdt 2.1: problema! E se i pacchetti ack e nack dovessero corrompersi? 
Il mittente potrebbe rimandare nel dubbio il pacchetto ma il destinatario deve poter distinguere da nuovi pacchetti e duplicati.
DUPLICATO: un pacchetto trasmesso e ricevuto e che viene ritrasmesso dal mittente.
soluzione: si aggiunge un bit per distinguere l'ultimo pacchetto non ancora confermato.


rdt 2.2: ci accorgiamo che nack non serve, si può usare ack confermando l'ultimo pacchetto ricevuto correttamente.
Es: se ricevente si aspetta il pacchetto con bit seq 1 e arriva corrotto allora manda un ack con bit seq 0.


rdt 3.0: ora il canale può anche perdere i pacchetti (di dati e di acknowledge).
Soluzione: mittente aspetta per un pò di tempo, se non riceve risposta reinvia il pacchetto.
Destinatario deve sempre fare attenzione ai pacchetti duplicati e confermare l'ultimo ricevuto correttamente.


Approccio rdt 3.0 è ottimo ma ha una grossa falla: si basa su stop and wait!
Andando ad aumentare il rtt (tempo di un pacchetto da destinatario a sorgente e incluso il ritorno) il tempo che il mittente è in attesa e non fa nulla aumenta molto, andando a sprecare collegamenti potenti.
Soluzione: pipelining, mittente può avere un numero finito (maggiore di 1) di pacchetti inviati da confermare.


Due tipi di pipelining: Go-Back-N e selective repeat (ripetizione selettiva). 


Go-Back-N:
Mittente può avere un massimo di N pacchetti non riconosciuti dal destinatario.
Destinatario manda ack cumulativi: dato ack di n conferma i pacchetti con numeri da n in giù.
Mittente ha un timer per ultimo pacchetto inviato: se scade ritrasmette tutti i pacchetti non ancora riconosciuti.
Dato: 
send_base numero primo pacchetto non confermato, nextseq numero di pacchetto minore non ancora usato per invio e window size la dimensione della finestra abbiamo che nextseq - send_base <= window size.
Se scade il timer tutti i pacchetti da send_base fino a nextseq sono reinviati.
Se arriva ack(n) imposto send-base a n+1.
Destinatario non usa un buffer => se si aspetta pacchetto n e riceve pacchetto n+qualcosa lo scarta.


Selective repeat:
Mittente può avere un massimo di N pacchetti non riconosciuti dal destinatario.
Destinatario manda ack per pacchetto: dato ack di n conferma il pacchetto con numero n.
Mittente ha un timer per ogni pacchetto: se scade rimanda solo quel pacchetto.
Dato: 
send_base numero primo pacchetto non confermato, nextseq numero di pacchetto minore non ancora usato per invio e window size la dimensione della finestra abbiamo che nextseq - send_base <= window size.
Se arriva ack(n) e n == send_base allora imposto imposto send-base a valore ultimo pacchetto non riconosciuto, altrimenti segno il pacchetto come riconosciuto ma non sposto la finestra.
Ora il destinatario possiede un buffer => se arrivano pacchetti non ordinati li memorizza e invia gli ack per quei pacchetti.


Selective repeat obbliga ad utilizzare un buffer per il destinatario, ma se mandassi 10 pacchetti e il primo dovesse perdersi dovrei rispedire un solo pacchetto, non tutti e 10.


Dalla discussione appena fatta su canali sicuri e pipelining possiamo introdurre
TCP: protocollo orientato alla connessione e affidabile.
Panoramica:
 - Punto a punto: un mittente e un destinatario.
 - Affidabile, basa su stream di bytes, usa il pipelining.
 - Connessione full duplex, ovvero il traffico è bidirezionale.
 - Orientato alla connessione, si inizia con un handshake.
 - Controllo di flusso.
 - Essendo basata su stream di byte il numero di segmento è il numero del primo byte contenuto nel segmento (es se segmento contiene byte da 10 a 999 allora il suo numero di sequenza sarà 10).
 - Ack cumulativi.


Essendo la connessione full duplex mittente oltre a mandare dati conferma con ack i pacchetti del destinatario, e quest'ultimo negli ack può mettere dei dati (quindi in entrambi i casi ho seq_num e ack) (vedere slide 60 cap 3).


Problema: Che valore diamo al timeout?
Def delle misure: 
 - SampleRTT è il tempo dall'invio del pacchetto all'arrivo del suo ack (simile a rtt ma può variare molto).
 - EstimateRTT: media pesata tra valore attuale di estimateRtt e l'ultimo valore di SampleRTT (con minor peso a quest'ultimo).
 - DevRtt è la deviazione del valore (quindi se samplertt e estimatertt stesso valore devrtt vale 0)
Intervallo di timeout: estimatertt + 4*devrtt (devrtt serve a rallentare il traffico se si nota che la rete ha grandi sbalzi, sintomo di problemi).


Tcp crea canale sicuro: pipelined, ack cumulativi, timer di ritrasmissione singolo.
(Timer è per pacchetto inviato non ack più vecchio, se scade ritrasmette però solo quest'ultimo).
(Destinatario manda come valore di ack il valore di byte che si aspetta, non num ultimo pacchetto ricevuto).


TCP ritrasmissione veloce: se tcp invia 4 pacchetti e riceve 3 ack duplicati probabile che primo pacchetto perso
 => ritrasmetto primo pacchetto senza aspettare la scadenza del timeout.


Controllo di flusso: mittente non deve mandare più pacchetti di quanto l'applicativo del destinatario riesce a gestire, altrimenti riempie il socket buffer del destinatario e perdo pacchetti.
Come fare? 
 => Destinatario mette nel campo rwnd numero byte disponibili nel proprio buffer.
    Window size del mittente sarà minore del campo rwnd.


Tcp è orientata alla connessione: handshake (3 vie, con campo syn) e chiusura connessione (con campo fin).


Controllo di congestione: Troppe sorgenti mandano troppi dati, più di quanti la rete riesce a gestire 
(diverso da controllo di flusso!).
Problemi: -lunghi delay. -pacchetti persi. -duplicati. -se pacchetti persi lavoro inutile di router e collegamenti.


Approcci al controllo della congestione:
 - End-to-End: non vi è un feedback dalla rete, si capirà la congestione dai pacchetti persi e dal delay.
 - network-asisted: router danno del feedback ai dispositivi (es atm abr).


TCP usa l'approccio end-to-end:
Ora window size deve essere minore sia di rwnd sia di cwnd.
cwnd serve a limitare la finestra (e di conseguenza i messaggi spediti) in base alla capacità della rete.


Implementato mediante slow start e congestion avoidance:
 - Inizialmente 1 messaggio ma crescita esponenziale (ad ogni ack ricevuto aumento di 1 msg la finestra).
 - Se timeout scade => riporto a 1 msg la finestra e cresce esponenzialmente fino a una soglia (di solito valore_precedente/2) poi cresce linearmente (1 msg ogni rtt). 
 - Se ack duplicati: cwnd dimezzato e in seguito crescita lineare (rete non è troppo congestionata).


Throughput di tcp? = 3/4 * (window_size/rtt) bytes/sec


Si è studiato che tcp è fair: date n reti connesse ad un collegamento K ogni rete avrà K/n bit di banda.


• Capitolo 4: Livello Di Rete, a questo livello si lavora su datagrammi
Livello massimo che si trova su ogni dipositivo, host e router.


Per fare in modo che un segmento passi da un host ad un altro deve passare per n router.
Il segmento viene incapsulato in un datagramma.


Come fa un router a capire dove mandare un datagramma? Indirizzo IP!


Da qui capiamo le due funzioni principali del livello di rete, implementate nei router:
 - inoltro (forwarding): spostare un pacchetto dall'input di un router ad un output del router.
 - instradamento (routing): determinare il percorso del pacchetto dalla sorgente al destinatario.


Come viene implementato ciò in un router?
 - routing mediante algoritmi di routing.
 - forwarding mediante la forwading table.


Vi possono essere dei servizi richiesti al livello di rete per creare un canale dal dest al mitt:
 - consegna garantita.
 - datagrammi arrivano in ordine.
 - banda minima garantita.
 - crittografia dei pacchetti.


Purtroppo Internet usa un modello di servizio "best effort", di conseguenza non implementa nessuno di questi servizi.


Una rete su datagrammi presenta un servizio a livello di rete SENZA connessione.
Una rete su circuito virtuale presenta un servizio a livello di rete orientato alla connessione.
NB: simile ai servizi TCP/UDP del livello di traposrto ma:
 - servizio da host a hos
 - non possiamo sceglierlo, dipende da come è stata costruita la rete.
 - implementato nel cuore della rete.


Vediamo i due tipi di rete
Circuiti virtuali:
 - il percorso da dest a mitt si comporta come un circuito telefonico, molto attento alle performance.
 - viene fatto un setup prima di inviare i dati.
 - i dati hanno un identificatore in base alla VC.
 - i router mantengono uno stato per ogni connessione.
 - risorse dei router e dei collegamenti vengono allocate per ogni connessione VC.
Va notato che il numero VC non è fisso, ogni router in base al numero VC di un pacchetto decide in quale interfaccia inviare il pacchetto e quale nuovo numero assegnargli.
 => per ogni vc bisogna andare ad aggiungere nuovi numeri ad ogni collegamento.
 => questo è il modo in cui i router mantengono uno stato per la connessione VC.
Si veda es forwarding table cap 4 slide 14.


Reti a datagrammi:
Usate nell'internet di oggi.
Non viene fatta una setup.
I router non mantengono uno stato per le connessioni tra host.
L'inoltro dei pacchetti viene fatto usando l'indirizzo IP dei pacchetti.


Problema: mediante iIPv4 vi sono 4 miliardi di indirizzi IP, come posso memorizzarli tutti in una tabella?
 => Non usiamo indirizzi IP completi, ma range di indirizzi IP, a cui andiamo ad associare un output del router.


Problema2: e se per un indirizzo IP più range sono validi?
 => Si sceglie l'interfaccia in base al più lungo prefisso che coincide con l'indirizzo IP.
Vedi cap4 slide 19


Perché si è preferito il modello di rete su datagrammi?
 - Dati scambiati tra computer con un servizio "elastico", senza limitazioni.
 - Non ha problemi se ci sono molti collegamenti diversi nel percorso.
 - Tutta la complessità viene portata ai bordi del Internet, lasciandone il cuore "stupido".


Ora che abbiamo capito come funziona il modello a datagrammi usato su Internet andiamo a vedere com'è fatto un router, che ricordiamo essere un componente "dumb":
Come detto prima i router sono implementati per poter offrire i servizi di forwarding e routing.
Buona parte del hardware serve per la funzione di inoltro.
Un router si compone di: processore di routing, porte di IO e una switching fabric.


Un processore di routing fa girare un algoritmo di routing (ne vedremo alcuni in seguito).


Porte di input:
si compongono di un ricettore di bit (livello fisico), un protocollo di livello di dati e uno switching decentralizzato (dato un datagramma guarda la tabella di inoltro nella sua memoria e lo manda ad una porta di output).
Idea: dividere il lavoro di capire a quale porta inoltrare il pacchetto alle porte di input.
E se i datagrammi arrivano più veloci della velocità di inoltro? Accodamento.


Switching fabric:
Componente che si occupa di spostare i pacchetti da porte di input a porte di output.
Switching rate: più è alto più pacchetti vengono spostati da porta di input a porta di output.
Ne esistono di 3 tipi:
 - via memoria: Pacchetto copiato nella memoria del sistema, ci penserà la cpu a spostare il pacchetto nella porta di output. Lo spostamento è di un pacchetto alla volta :(
 - via bus: da porta di input a porta di out via bus condiviso. Un pacchetto alla volta ma bus può essere molto veloce.
 - via rete interconnessa: Basata su reti banyan, più bus interconnessi. Quando si deve mandare un pacchetto si chiudono i crosspoint e il pacchetto andrà nella corretta direzione. In alcuni casi invio pacchetti in parallelo.


Porte di output:
Identiche a porte di input ma speculari, al posto dello switching decentralizzato vi è un buffer che funge da coda se arrivano più pacchetti di quanti la porta riesce a immettere in rete.


Se rateo di switching più veloce del tempo di immessione del pacchetto in rete avvengono accodamenti e perdita di pacchetti.


Se la switching fabric è più lenta del rateo di switching: coda nelle porte di input, possibile delay e perdita.
Head-of-the-Line (HOL) blocking: pacchetti in testa alla coda che non possono procedere bloccano anche i pacchetti successivi, anche se possono andare in porte di output vuote. (vedi cap 4 slide 31, figura a dx).


Visto come funziona un router possiamo ora introdurre il protocollo di rete:
IP, Internet Protocol:
Definisce formato datagramma (versione ip, lunghezza, checksum, TTL, ip sorg e ip dest ecc)


MTU: max transfer size, dimensione massima di un datagramma per quel collegamento.
Problema: e se un router dovesse inviare un datagramma con length > MTU?
 => frammentazione! Da un datagramma se ne ottengono n più piccoli, in maniera tale che possano essere inviati in quel collegamento.
 => riassemblaggio: Il destinatario finale riassembla il datagramma originale andando a vedere il flag di frammentazione e usando l'identificatore a 16 bit del header dei datagrammi.


Come detto prima l'instradamento si basa sull'indirizzo ip del destinatario.
Cos'é un indirizzo ip? identificatore a 32 bit di un host, uno per ogni interfaccia di un router.
Interfaccia: connessione tra host/router e collegamento fisico (router tipicamente #interf > 1).
Visualizzato come 4 numeri da 1 byte ciascuno (da 0 a 255).


Indirizzo ip si divide in due parti: primi n bit vengono detti "parte della sottorete".
I restanti 32-n bit più bassi sono detti "parte del host".
Si noti che il numero di bit dedicati ad una sottorete è arbitrario.


Ma cos'è una sottorete?
 => interfacce dei sistemi che hanno i bit della parte della sottorete identici.
 => possono connettersi tra di loro SENZA intervento del router.
Si veda cap4 slide 40 immagine a dx e slide 41 immagine a dx.


Ma dato un indirizzo ip come distinguo le due parti?
 => CIDR: formato indirizzi ip diventa a.b.c.d/x dove x num. bit parte della sottorete.


ISP hanno delle porzioni di indirizzi ip, i quali andranno distribuiti tra le sottoreti dei clienti.
Es se ISP ha indirizzo con subnet /20 (quindi 12 bit come vuole) può creare delle sottoreti con subnet 
/23 (primi 20 bit uguali a subnet ISP, 3 bit definiti dalla ISP e restanti 9 per i dispositivi).
Instradamento Gerarchico!.


Ma data una sottorete con una porzione di indirizzi ip, come fa l'host a ottenere un indirizzo ip?
 => protocollo DHCP!


DHCP: protocollo per ottenere indirizzo ip dinamico da server.
NB: DHCP è un protocollo a livello applicativo.
Permette ad un host di connettersi ad una nuova rete e ottenere un indirizzo ip dinamicamente (non deve essere configurato a mano).
Permette anche un meccanismo di "affitto" di un indirizzo IP.
Step:
 - pc si connette ad una nuova rete.
 - broadcast messaggio DHCP discover, "mi serve un indirizzo ip".
 - DHCP server risponde/rispondono con DHCP offer sempre in broadcast(contiene IP, sorgente, next-hop router, DNS, maschera, tempo di lease se necessario ecc).
 - pc sceglie l'offerta che preferisce e risponde con un DHCP request, contenente i parametri dell'offerta scelta.
 - DHCP risponde al messaggio di richiesta con un DHCP ACK.
La connessione può essere più veloce usando solo i messaggi DHCP request e DHCP ACK, in tal caso i parametri saranno inviati dal server al host nel ACK.


Problema: Come facciamo se una sottorete ha troppi host e eccede la sua maschera, e come facciamo ad evitare che il numero di host superi il numero di host permessi da IPv4?
 => NAT!
NAT: network address translation
Dato un router che connette una sottorete ad internet se questo viene impostato come un router nat:
 - Tutti gli host della rete avranno indirizzo IP 10.0.0.x/24
 - Datagrammi con sorg e dest nella sottorete funzioneranno come solito.
 - Se un datagramma ha dest al di fuori della sottorete gli verrà assegnato un indirizzo IP unico, che è lo stesso indirizzo IP dell'interfaccia del router verso internet.
Vedere cap 4 slide 56.


Perché fare ciò? per una sottorete ora basta usare un solo indirizzo IP!
Questa porta a diversi vantaggi in termini di scalabilità, cambiamento di indirizi o ISP.


Ma come faccio a distinguere il traffico di èiù host della sottorete?
Il router identifica i pacchetti da/verso più host in base a che porta assegna ai pacchetti in uscita.
Router nat ha una NAT Translation Table:
Ad ogni (Nat IP, # porta) corrisponde (host ip, # porta).
Quindi ad ogni pacchetto uscente sostiuisce indirizzo ip e porta con nat ip e nuova porta.
Ad ogni pacchetto entrante sostituisce indirizzo ip nat e porta con indirizzo ip e porta originale.


Problema: client vuole connettersi ad un server che si trova in una sottorete di un server NAT, quindi conosce solo indirizzo IP Nat del router.
 => soluzione 1: configurare NAT in modo tale che richieste di connessione vengano sempre mandate al server in automatico.
 => soluzione 2:  Internet Gateway Device (IGD) Protocol: permette a host in una nat di conoscere indirizzo IP pubblico.
 => soluzione 3: usare un ritrasmettitore (es. Skype). vedere cap4 slide 63.


ICMP: protocollo usato da host e router per scambiarsi informazioni a livello di rete.
Ogni messaggio ICMP è composto da un tipo e da un codice, da questi due capiamo il messaggio.
Può includere 8 byte per IP datagramma che ha causato l'errore.
Es: rtt misurato mediante serie di segmenti UDP verso dest con TTL sempre maggiore, per capire quando si è arrivati al destinatario si va a vedere quando arriva il messaggio ICMP.


Si sta cercando di spostare indirizzi IP da IPv4 a IPv6.
 - più indirizzi.
 - header migliorato (es. rimosso checksum, campo priorità).
 - nuove impostazione per migliorare il servizio.
 - Non è più permessa la frammentazione.


Problema: se datagramma IPv6 giunge ad un router che non supporta datagrammi IPv6?
 - Tunneling: datagramma IPv6 viene trasportato in un datagramma IPv4 come suo payload fino al prossimo router che supporta IPv6.


Finito il discorso di inoltro e come funziona l'indirizzo IP è ora di parlare di
Algoritmi di routing.
Notiamo una cosa importante: una rete può essere vista come un grafo, con costo indirettamente proporzionato alla velocità del collegamento.
Algoritmi di routing trovano il percorso con peso minore tra due host.


Si possono dividere in base a 
informazione della rete
 - globale : ogni router conosce il grafo della rete. Algoritmi link state!
 - decentralizzato: router conoscono solo costo dei vicini, si scambiano informazioni. Algoritmi distance vector!
e
rete
 - statica: rete cambia poco nel tempo
 - dinamica: cambio costo collegamento e aggiunta/rimozione di router avvengono spesso.


Algoritmo di Dijkstra: un esempio di algoritmo link state.
Ogni router conosce la forma della rete e il costo di ogni link.
Router ottiene percorsi con costo minimo per ogni altro router della rete.


Algoritmo di Bellamn-Ford: un esempio di algoritmo distance vector.
Notiamo che il cammino minimo da x a y si ottiene trovando il minimo tra il costo per arrivare da x ad un suo vicino v + costo cammino minimo da v a y.
In formula: 
Dato Dx(y) := cost of least-cost path from x to y
Allora Dx(y) = min {c(x,v) + Dv(y) } per qualunque v vicino di x.


I router calcolano il percorso con il costo minimo con gli altri router in base alle informazioni dei loro vicini, se trovano un nuovo percorso minimo mandano l'insieme dei percorsi minimi, detti distance vector, ai loro vicini.
Quando un router nota che un percorso a cui è collegato ha cambiato peso o un suo vicino gli ha mandato dei nuovi percorsi minimi il router ricalcola il distance vector, e se nota delle differenze lo inoltra ai suoi vicini.


Problema: nel mondo vi sono circa 600 milioni di router, non possiamo costruire la tabelle su grafi così grossi.
 => Routing gerarchico!
Rispetta l'idea di internet come rete di reti.
Ogni admin di rete può gestire il routing nella propria rete.
Come viene implementato?
 => Insieme di router raccolti in una regione detta Sistema Autonomo (abbr. AS)
 - un ISP consiste di una o più AS.


Router nella stessa AS hanno stessi protocolli di routing: intra-AS routing.
Gateway router: Ai bordi di una AS, collegano tra loro più AS. inter-AS routing.




Ma allora come fa un router che deve inviare un datagramma destinato al di fuori della AS?
1) deve capire quali destinazioni sono raggiungibili dalle AS vicine.
2) Propagare questa info a tutti i router della AS.
3) Trovare il costo minimo per il router gateway della AS che permette di raggiungere la destinazione.
4) Aggiungere alla forward table riga con subnet della destinazione e interfaccia per il router di gateway.


Es algoritmi di intra-Routing:
RIP: algoritmo di distance vector, con DV scambiata tra router ogni 30 sec.
OSPF: algoritmo di link state, ha feature avanzate come più percorsi in base al servizio, sicurezza e multicast.
OSPF gerarchico: identico a OSPF ma include una gerarchia a due livelli per gestire reti complesse (locali e colonne)
Vedasi cap4 slide 122.


BGP: algoritmo inter-AS, usato per gestire l'intera internet.
Permette ad ogni AS di ottenere:
 - informazioni di raggiungibilità dalle vicine AS. eBGP
 - propagare raggiungibilità a tutti i suoi router. iBGP
 - trovare i percorsi migliori in base a raggiungibilità e policy.


Supponiamo che AS3 voglia dire ad AS1 di una nuova subnet raggiungibile:
 - I loro router di gateway aprono una sessione eBGP, AS3 manda il prefisso raggiungibile al router di AS1.
 - Il router mediante iBGP invia la nuova raggiungibilità a tutti i router di AS1.
 - Supponiamo AS2 collegata ad AS1, AS1 mediante eBGP manda nuova subnet raggiungibile ad AS2.
Quando un router trova un nuovo prefisso lo aggiunge alla sua forwarding table.


Quando si vuole avvisare una nuova subnet raggiungibile vi sono degli attributi quali:
 - AS-PATH: percorso di AS da attraversare per raggiungere quel prefisso.
 - NEXT-HOP: indirizzo ip router da cui inizia AS PATH. (es di prima per AS2 sarà router gateway di AS1)


E cosa succede se un router trova più modi per raggiungere una subnet? Sceglie percorso migliore:
 - In base alle policy.
 - AS-PATH più breve
 - NEXT-HOP più vicino (hot potato routing).
 - altro


Mettendo tutto insieme, come fa una nuova sottorete a essere raggiungibile dai router?
Supponiamo di usare BGP e OSPF come intra-AS.
 - Messaggi BGP contenenti prefisso e percorso.
 - Router sceglie un percorso per quel prefisso.
 - Router usa OSPF per trovare il percorso minimo al NEXT-HOP router.
 - Trova l'interfaccia e aggiunga alla tabella di forwarding (prefisso, interfaccia).


Le policy del router possono includere anche NON accettare percorsi attraverso AS* o non inoltrare raggiungibilità a quella AS.




Nuovo meccanismo:
Broadcast: un nuovo vuole mandare un paccheto a tutti gli altri router della sua rete.


Come implementare il broadcast?
 - Duplicazione alla sorgente: molto inefficente. Può causare cicli infiniti o causare perdite di altri pacchetti.
 - RPF: quando ad un router arriva un pacchetto broadcast lo inoltrerà ad i suoi vicini solo se arrivato da percorso più breve tra sorgente e lui, altrimenti non lo considera.
 - spanning tree: si costruisce un albero tra sorgente e altri router, non vi sono pacchetti duplicati.


Si possono costruire gli spanning tree usando un nodo come radice, gli altri router si uniscono all'albero inviando un pacchetto verso quel nodo centrale, appena il pacchetto arriva ad un nodo che fa parte dell'albero quello sarà il suo percorso. chiamati Center-Based tree.
Vedasi cap 4 slide 137.




Nuovo meccanismo:
Multicast: un nuovo vuole mandare un paccheto a host membri di un gruppo. 
Come implementarlo? 
 => costruire un albero che connette tutti i router che possiedono host che fanno parte di quel gruppo.
Approcci:
 - source-based: un albero per ogni sorgente (es Dijkstra, RPF).
 - group-shared: unico albero per tutti (es center-based).


Come mando datagramma multicast?
 => tunneling: datagrammi multicast inseriti in datagrammi unicast.


DVMRP: protcollo routing multicast.
Si basa sul RPF con un sistema flood e prune:
 - Pacchetto inviato a tutti e inoltrato secondo le regole del RPF.
 - prune: se un sotto albero non possiede router con membri viene fatta un'operazione di pruning: manda un messaggio verso la sorgente dicendo che quel sottoalbero non ha membri, il primo router dell'albero a ricevere quel messaggio si ricorderà di non mandare più messaggi multicast di quel gruppo verso quel sottoalbero. (cap 4 slide 143).
 - soft state: periodicamente (circa 1 minuto) i sottoalberi a cui è stata fatta un'operazione di pruning vengono reinseriti, questo evita il caso che vi siano aggiunti dei membri al gruppo che non ricevono pacchetti perché sono in un sottoalbero pruned.


PIM: altro protocollo multicast.
Lavora in base alla distribuzione dei router del gruppo:
 - densi: membri raggruppati, molto vicini tra di loro.
 - sparsi: num sottoreti molto piccolo rispetto alla dimensione della rete, membri sparsi.
Si usano due approcci:
 - membri densi: di base tutti i router membri, sistema RPF con pruning.
 - membri sparsi: router devono unirsi esplicitamente, center-based tree.


• Capitolo 5: Livello Di Collegamento, a questo livello si lavora su frame
Terminologia: 
 - hosts e routers: nodi.
 - canali di comunicazione che collegano due nodi adiacenti: collegamenti (a cavo, senza cavo, lan ecc).


Compito di questo livello: trasportare i frame da un nodo ad un altro nodo adiacente.
Diversi collegamenti, diversi protocolli.


Servizi del livello di collegamento:
 - framing: incapsulare datagrammi in frame.
 - protocolli per accesso su canali condivisi.
 - controllo errori: usato solo nei wireless per l'alta probabilità di errore.
 - half-duplex: entrambi nodi possono trasmettere nello stesso canale ma non simultaneamente.
 - full-duplex: entrambi nodi possono trasmettere nello stesso canale simultaneamente.


Dove viene implementato tutto ciò?
 => in ogni nodo è presenta una NIC (network interface card), una scheda di rete.


Come possiamo fare un controllo dell'errore che sia sicuro?
 - Bit di parità: frame viene visto come sequenza di bit, imposto bit di parità a 1 o 0 in modo tale da avere numero bit a 1 pari.
Ricevente controlla se numero di bit a 1 sia pari, in caso negativo siamo in presenza di un errore.
PROBLEMA: se due bit cambiano valore? errore non viene visto.


 - Bit di parità a due dimensioni: come prima ma frame viene visto come matrice di bit, calcolo bit di parità per ogni riga e colonna.


 - Checksum: visto precedentemente, frame visto come strnghe di 16 bit e sommate e ne viene fatto il complemento a 1.


 - CRC (Cyclic redundancy check): più potente. Per prima cosa mittente e dest si accordano su un numero G di r+1 bits. Quando il mittente deve inviare un pacchetto di d bits di dati gli aggiunte r bits ridondanti in maniera tale che la stringa di bits <d,r> sia divisibile per G. Destinatario verifica se il frame ricevuto sia divisibile per G, in caso negativo abbiamo trovato un errore.


Problema: come possiamo gestire collegamenti condivisi tra più nodi senza causare collisioni?
 => Protocolli MAC.


Mac: Multiple Access Protocols.
Cosa succede se due nodi iniziano a trasmettere sullo stesso collegamento condiviso? Avviene una collisione, i dati trasmessi sono illeggibili.


Dato un canale di R bps idealmente vogliamo che:
 - quando un solo nodo vuole trasmettere, trasmette a R bps.
 - quando N nodi vogliono trasmettere, mediamente trasmettono nell'arco di tempo totale a R/N bps.
 - completamente decentralizzato.
 - semplice.


Vedremo ora 3 diversi tipi di protocolli MAC:


1) Channel partitioning MAC protocols: "dividiamo il canale in pezzi e ad ogni nodo diamo un pezzo di canale"
TDMA: accesso nel canale in round, ad ogni nodo viene dato un lasso di tempo prestabilito per trasmettere ad ogni round.
FDMA: canale diviso per frequenze, ad ogni nodo viene assegnata una frequenza.
Problema: e se un singolo nodo vuole trasmettere? In entrambi i casi sarà costretto a trasmettere a R/N bps, il resto dei bps non utilizzati dagli altri nodi sono sprecati.


2)Random access protocols: Quando un nodo deve inviare, invia a R bps. Non vi è una coordinazione a priori. Se due nodi decidono di trasmettere simultaneamente: collisione.


Slotted ALOHA: supponiamo frame della stessa divisione e il tempo diviso in slot tali che in uno slot si riesce ad inviare un frame.
Quando un nodo ottiene un frame da inviare:
 - inizia a trasmettere all'inizio di uno slot di tempo.
 - Se non avvengono collisioni riesce a trasmettere il frame.
 - Se avviene una collisione il nodo proverà a trasmettere in uno slot successivo, viene data una probabilità P che il nodo provi a trasmettere in un dato slot.
Ottimo se un singolo nodo vuole trasmettere, problema con tanti nodi molte collisioni e se la probabilità P è molto bassa molti slot non saranno utilizzati.
Si può calcolare efficenza (slot utilizzati con successo/slot totali) con molti nodi e ottenere 37%, troppo bassa!


ALOHA puro: identico a Slotted ALOHA ma ora non vi è più una sincronizzazione mediante slot, più semplice ma probabilità di collisione è molto più alta. Vedere cap5 slide 27.
Efficenza con molti slot è scesa a 18%.


CSMA (carrier sense multiple access): prima di inviare controllare se canale è in utilizzo, se canale libero trasmetti. Possono avvenire collisioni ma dipendono dalla velocità di propagazione.


CSMA/CD (collision detection): Quando si trasmette si cerca di capire se sta avvenendo una collisione (facile in reti a cavo, difficile nelle wireless).
Quando un nodo riceve un frame da inviare:
 - NIC controlla il canale, se occupato aspetta finché non diventa libero, altrimenti trasmetti subito.
 - Se trasmetto intero frame senza collisioni abbiamo finito.
 - Se avviene una collisione ferma la trasmissione e invia un segnale di jam (avviso che è avvenuta una collisione).
 - Dopo la collisione entra in uno stato di attesa esponenziale binaria: alla n-esima collisione sceglie un numero k tra 0 e 2^(n)-1 e attende per k*512 bit/banda (collegamenti veloci portano a tempi di attesa brevi, tante collisioni a tempi di attesa lunghi).
Molto più performante di ALOHA e più semplice e decentralizzato.


Abbiamo visto che i protocolli a suddivisione di canale hanno il problema che con un singolo nodo non permettono di sfruttare a pieno la banda, e purtroppo i protocolli ad accesso casuale non sono ottimi per tanti dispositivi (aumenta la probabilità di collisione), quindi si è deciso di trovare una via di mezzo con i protocolli a turni.


3)“Taking turns” MAC protocols: uso del canale in base ai turni.
polling: un nodo viene eletto a master, gli altri nodi sono slave. Il master "invita" i nodi a trasmettere, se non hanno da trasmettere il turno passa allo slave successivo.
problema: overhead, single point of failure (master).


Token passing: chi controlla il token può trasmettere per un certo lasso di tempo per poi passare il token al nodo successivo, se non ha nulla da trasmettere passa subito il token.
problema: overhead, single point of failure (token).


Ora che abbiamo visto i protocolli principali andiamo a vedere un esempio pratico:
Reti ad accesso cablato:
Sul canale di downstream sarà soltanto il cmts (cable modem termination system) a trasmettere in broadcast.
Sul canale di upstream tutti gli utenti potrebbero dover trasmettere, MAC.


Ma come vengono suddivisi i due flussi sullo stesso cavo? mediante FDM per creare upstream e downstream.
Per upstream viene utilizzata una variante del TDM: slot assegnati dal CTMS in base alle richieste degli dispositivi degli utenti.
Richieste per slot upstream vengono fatte in slot appositi usando CSMA/CD. In downstream viene mandata in seguito una map con gli assegnamenti.




Problema: Nel livello rete (livello precedente) abbiamo detto che l'indirizzamento si basa un indirizzi IP, e per il livello di collegamento?
 => indirizzi MAC.


indirizzo mac: unico per ogni NIC, indirizzo a 48 bit. Ha una funzione locale, serve a portare un frame da un'interfaccia ad un'altra connessa fisicamente.
NB: router con più interfacce -> più NIC -> più indirizzi MAC.


Indirizzi MAC sono indirizzi portabili: se host cambia sottorete indirizzo MAC non cambia, IP cambia.


Problema: Dato un host che vuole mandare un pacchetto ad un host e conosce il suo indirizzo IP, come può ottenere il suo MAC per mandare il frame?
 => tabella ARP.


ARP: address resolution protocol
Ogni nodo possiede una tabella ARP, una mappa della sua LAN per cui ad ogni indirizzo IP associa un indirizzo MAC e un TTL.


Host A vuole indirizzo MAC di host B, di cui conosce indirizzo IP:
 - Manda un frame ARP query in broadcast (indirizzo MAC tutte F) e contenente indirizzo IP di B.
 - B riceve il pacchetto ARP e risponde inviando ad A il suo indirizzo MAC. (ora frame unicast).
 - A salva nella sua arp table <indirizzo ip B, indirizzo MAC B, TTL>
Questo protocollo è plug and play, non richiede configurazione.


Quale può essere considerata la tecnologia principale delle LAN?
Ethernet (veloce e poco costosa).
Due diverse topologie:
 - a bus: host condividono un unico cavo coassiale.
 - a stella: più recente, host connessi mediante switch, ognuno ha un cavo riservato.


Problema: Ethernet non utilizza un handshake e la trasmissione dei bit non è perfetta, come fare?
 => frame ethernet include un preambolo, 7 byte con pattern 10101010 per poter permettere al ricevente di sincronizzarsi con il frame. (ultimo byte 10101011, 11 indica che dopo inizia il vero frame).


Va notato che ethernet è senza connessione (no handshake) e non affidabile (non vi sono procedure di acknowledge).
Se vi sono più nodi su un unico collegamento si usa CSMA/CD.


Ora parliamo degli switch:
Switch, dispositivi a livello di collegamento con funzionalità simili ai router per il livello di rete.
Fa store-and-forward dei frame, esamina indirizzo MAC del frame e invia ad uno o più uscite il frame.
Usa CSMA/CD per accedere al collegamento.


Particolarità degli switch sono:
 - trasparenti: nodi non conoscono la presenza degli switch.
 - plug-and-play: utilizzano un meccaniso di auto apprendimento.


Se arrivano molti frame da un host? Switch hanno dei buffer per i frame.


Dato un frame con indirizzo MAC di un host A, come fa lo switch a capire dove inviare quel frame?
 => Usa una switch table, con righe <Indirizzo MAC, Interfaccia, TTL>


E come fa lo switch a capire su quali interfacce si trovano certi dispositivi?
Self-learning: dal traffico gli switch imparano su quali interfacce si trovano i nodi.
Es. da interfaccia 1 arriva una frame con mitt A e destinatario A', switch aggiunge alla switch table che l'indirizzo MAC di A si trova sull'interfaccia 1. Frame con destinatario A andranno sull'interfaccia 1.


Problema: e se uno switch non conosce su quale interfaccia deve mandare un frame?
 => flood: invia il frame su tutte le interfaccia tranne quella da dove è arrivato il frame, se un nodo riceve un frame con destinatario MAC diverso dal suo scarterà il frame.


Si possono anche interconnettere più switch, il meccanismo non cambia.


Introduciamo le VLAN con questo caso:
immaginiamo che una scuola con più dipartimenti sia formata da switch interconnessi, uno per dipartimento. cap 5 slide 74.
Questo causa dei problemi: tutto il traffico broadcast (arp, dhcp, ecc) passerà per tutta la scuola spesso inutilmente. E se un docende cambia ufficio (ovvero posizione nella scuola e quindi switch) ma non dipartimento (nel senso he lavora/utilizza stessi servizi di prima) il suo traffico dovrà viaggiare su più switch.
E se creiamo un dipartimento nuovo e piccolo? dobbiamo allocare switch e risorse che andranno sprecati.


Come possiamo risolvere questi problemi? VLAN!
Vlan: Virtual Local Area Network
Un singolo switch che supporta VLAN può essere configurato per definire più LAN virtuali su un'infrastruttura per LAN Singola.
Come si implementa ciò?
 => VLAN basata su porte: posso ragruppare più porte dello switch e definire una LAN virtuale per ogni gruppo.
Es. porte 1-10 Dipartimento ingegneria, 11-15 Informatica ecc.


Vantaggi:
 - Isolamento traffico: frame per dipartimento di informatica potrà viaggiare solo in quella LAN.
 - Appartenenza dinamica: porte vengono assegnate ai gruppi dinamicamente.


E come passa il traffico tre le vlans? mediante un router contenuto nello switch.


E se le porte di un singolo switch non dovessero bastare?
 => trunk port: porte usate per connettere più switch vlan e trasportare i frame.
 => bisogna aggiungere al frame un nuovo campo al header (contiene VLAN ID info).


MPLS: Multiprotocol label switching
idea: rendere più veloce l'inoltro utilizzando una label di  lunghezza fissa invece che un indirizzo IP.
Più veloce andando a vedere l'identificatore (invece che il prefisso IP).
Idea simile ai circuiti virtuali ma viene comunque usato l'indirizzo ip.


I router che supportano MPLS usano una MPLS table e decidono in base alla label (non guardano nemmeno indirizzo IP).
flesibilità: percorso IP e MPLS potrebbe essere diverso. inolte MPLS si basa sul valore di destinazione sia di sorgente (IP guarda solo indirizzo destinazione).


Meccanismo fast reroute: cambia valori nelle MPLS table se nota che ci sono problemi con alcuni collegamenti (si sposta il traffico).


Protocollo RSVP-TE usato da un router per inviare info e creare le MPLS table (non lo vedremo in dettaglio).


Reti dei data center: tante applicazioni, un sacco di traffico e carico di lavoro.
 - Load balancer: livello applicativo, riceve le richieste dei client e distribuisce il carico di lavoro tra i server, deve stare attendo a non sovraccaricare di lavoro un server.
 - Switch interconnessi: aumenta il throughput e aumenta l'affidabilità (se un ceollegamento fallisce ne abbiamo tanti altri).


Cap 5 slide 91-98 illustra il percorso di vari servizi su tutti i livelli, ottimo per ripassare o in caso di dubbi.


• Capitolo 6: Reti Wireless
Quando si parla di reti wireless si definiscono questi componenti:
 - host wireless: laptop, telefoni, ecc. Nota che wireless != mobilità, potrebbero anche essere stazionari.
 - base station: connesse all'infrastruttura di rete, collegano i dispositivi wireless al resto della rete.
 - collegamento wireless: connette host e base station. Access multiplo.


Vi sono due tipo di rete wireless:
 - infrastruttura: base stations connettono dispositivi alla rete. Handoff: host cambia base station durante la mobilità.
 - ad hoc: non vi sono base station, nodi possono trasmettere solo ad altri nodi nel raggio del collegamento wireless. Es bluetooth.


Caratteristiche dei collegamenti wireless sono:
 - attenuarsi del segnale wireless distanziandoci dalla sorgente (o a causa di interferenze).
 - interferenza da altre sorgenti.
 - Propagazione a più percorsi (ostacoli fanno rimbalzare il segnale).
 - problema terminale nascosto (A comunica con B, B con C ma A e C non si vedono e potrebbero interferire tra di loro).


Due valori importanti sono:
 - SNR (signal-to-noise ratio): maggiore snr -> più pulito è il segnale da rumori.
 - BER (bit error rate): più è alta -> maggiore probabilità di errori.
Quando ci connettiamo si cerca di trovare collegamento wireless che massimizza throughput e SNR e minimizza BER.




Un modo per gestire gli accessi multipli è mediante il protocollo
CDMA: Code Division Multiple Access
Ad ogni utente è assegnato un codice.
Viene usata la tecnica del code set partitioning:
 - tutti gli utenti usano le stesse frequenze, ma ogni utente usa il suo codice per inviare i dati.
 - Con codici correttamente impostati più utenti possono trasmettere senza causare interferenze.


Segnale codificato: sommatoria dati originali * codice


Vedere cap6 slide 17-18




Protocollo wireless interessante è il 802.11 conosciuto come wireless LAN
Usa CSMA/CA per accesso multiplo.
Architettura:
 - Host wireless comunicano con access point (i quali fungono da base station)
 - Basic Service Set (BSS): detta cella, contiene un access point e tutti gli host connessi ad essa.


Problema: come fanno più access point che usano la stessa frequenza a non interferire tra di loro?
 => frequenza divisa in 11 canali, per ogni AP si assegna un canale.


Host devono connettersi ad un AP, come fanno?
Scanning passivo:
 - AP mandano periodicamente nel canale dei beacon frame contenenti SSID (nome AP) e MAC address.
 - host sceglie AP con cui vuole associarsi.
 - host deve ottenere indirizzo IP, usa DHCP.
Scanning attivo:
 - host invia Probe Request in broadcast per vedere tutti gli AP con cui può connettersi.
 - Ogni AP invia Probe Responde frame (SSID e MAC).
 - Host sceglie AP e invia Association Request.
 - AP invia Association Response, accetta richiesta di connettersi.


Come gestiscono le lan wireless l'acesso multiplo?
Verrebbe da usare CSMA/CD ma c'è un problema! Le collisioni sono molto difficli da individuare nelle reti wireless..
 => usiamo CSMA/CA, aka evitiamo le collisioni ad ogni costo.


Vediamo come fa un mittente ad inviare usando CSMA/CA:
 - Mittente riceve frame da inviare.
 - Se canale non è utilizzato per un tempo DIFS allora invia intero frame.
 - Se canale occupato inizia un tempo di backoff (binario esponenziale) ma timer scende SOLO QUANDO CANALE NON è ATTIVO.
 - Appena finisce il timer invia il frame.
 - Se non arriva ACK aumenta intervallo di backoff e riprova ad inviare.


Mentre il destinatario:
 - se ricevi frame OK
 - Se canale non è utilizzato per tempo di SIFS allora invia ACK.


Possibilità di collisione diminuita di parecchio ma si può fare di meglio
Protocollo MAC CSMA/CA permette anche di essere utilizzato per "riservare" il canale ad un host:
Quando un host vuole trasmettere invia un pacchetto RTS alla BS usando CSMA (se collisione poco importa, lo ritrasmettiamo).
BS accetta richiesta e invia pacchetto CTS in broadcast.
CTS ha due significati:
 - per chi ha richiesto il canale la possibilità di iniziare a trasmettere.
 - per altri host ora sanno che il canale sarà occupato per un certo lasso di tempo.


Cosa avviene in caso di mobilità all'interno della LAN?
 - host cambia AP a cui è connesso.
 - stessa sottorete, indirizzo IP non cambia.
 - switch mediante self-learning aggiorneranno le loro tabelle.


Le LAN wireless possiedono anche i seguenti servizi avanzati:
 - adattamento del rateo: Se quando il dispositivo si sposta SNR dovesse diminuire il valore allora cambia collegamento wireless per aumentare SNR e diminuire BER (anche se dovesse diminuire throughput).
 - gestione energia: nodo dice al AP che si "addormenta" mediante frame per un certo tempo. AP non invia frame a questo nodo. Finito il tempo nodo si accende e Ap manda beacon frame contenente tutti i frame che deve inviare a quel nodo. Se lista vuota nodo può addormentarsi di nuovo.


Protocollo 802.15 definisce le reti ad area personale (bluetooth), infrastruttura ad hoc con raggio corto (max 10m) e un sistema master/slave (dove gli slave devono fare richiesta al master per poter trasmettere).


Andiamo ora a definire i componenti dell'architettura della rete di cellulari:
 - celle: coprono regioni geografiche, si compongono di una BS e degli user mobili connessi mediante collegamento wireless alla BS.
 - Mobile Switching center (MSC): connettono telefoni alla rete telefonica, si occupano anche di setup e gestire la mobilità.


Come gestisco gli accessi multipli tra cellulari e BS?
 - uso combinazione di FDMA e TDMA (divido in base a frequenze e tempo).
 - CDMA


Architettura 2G era un'architettura telefonica esclusivamente per voce.
Con 3G si unisce voce e accesso a internet, ma come?
 => La nuova rete internet lavora in parallelo con la vecchia rete per connessione di voce. 
 => Non cambiamo strutture vecchie e la rete dati può operare in parallelo senza interferenze.


Parliamo ora della mobilità 
Da un punto di vista della rete, un'alta mobilità significa che l'utente può passare per più access point, mantenendo comunque la connessione stabilita (non deve chiedere nuovo ip, rifare handshake tcp ecc).


Introduciamo prima qualche termine:
 - home network: rete permanente dell'host.
 - home agent: router della home network che svolgerà funzioni di mobilità quando l'host lascerà la rete.
 - indirizzo permanente: indirizzo IP permanente del dispositivo, anche quando lasceà la home network.
 - corrispondente: colui che vuole comunicare con l'utente mobile.
 - visited network: nuova rete visitata dal dispositivo mobile.
 - care-of-address: indirizzo della rete visitata.
 - foreign agent: router della visited network che svolgerà funzioni di mobilità.


Come gestiamo il caso di un corrispondente che vuole scrivere ad un utente mobile e non sa dove si trova (ma ha il suo indirizzo IP permanente)?
 - idea 1: gestione del routing, router si inviano tabelle contenenti gli indirizzi permanenti dei dispositivi che stanno visitando la loro rete.
 - idea 2: gestione end-system, saranno gli end system a gestire la mobilità.


Essendo l'idea 1 non scalabile (milioni di dispositivi mobil che si spostano continuamente creano un traffico enorme) si è optato per la seconda idea.


Prima di vedere gli approcci principali introduciamo una nuova azione della mobilità
Registrazione: 
 - quando un dispositivo mobile entra in una visited network contatta il foreign agent, "sono qui".
 - Foreign agent contatta home agent, "questo tuo utente è da me"
Ora home agent sa dove si trova dispositivo mobile.


Mobilità mediante routing indiretto:
 - corrispondente manda pacchetti alla home network (indirizzo IP permanente).
 - home agent vede che i pacchetti sono indirizzati al dispositivo mobile e grazie alla registrazione sa dove si trova.
 - home agent inoltra i pacchetti al foreign agent.
 - foreign agent riceve i pacchetti e li manda al dispositivo mobile, il quale li manda direttamente al corrispondente.
Si possono notare delle peculiarità:
 - il concetto di mobilità è trasparente al corrispondente, non conosce nemmeno dove si trova il dispositivo.
 - Si possono mantenere le connessione anche se il dispositivo dovesse di nuovo spostarsi (basta rifare la registrazione e home agent sa nuova posizione).
Problema: triangle routing (cap6 slide 50 si vede bene), se mobile nella stessa subnet del corrispondente percorso del pacchetto potrebbe essere più breve.


Mobilità mediante routing diretto:
 - corrispondente richiede e riceve care-of-address del host dal home agent.
 - l'invio e la ricezione dei pacchetti avvengono usando il nuovo indirizzo care-of.
Buona notizia: abbiamo risolto il problema del triangle routing.
Problemi: mobilità non più trasparente, cosa succede se host cambiasse di nuovo rete?


Mobilità mediante routing diretto con ancora:
 - Se host dovesse cambiare di nuovo rete il foreign agent della prima rete visitata fa da ancora.
 - pacchetti arrivano all'ancora, la quale li invia al foreign agent della nuova rete.
 - se host cambia tante volte rete si crea una catena di ancore le quali si inoltrano i pacchetti. 


Mobile IP: principale protocollo per la mobilità
Basato su routing indiretto.
Registrazione avviene nei seguenti passi:
 - foreign agent manda messaggio ICMP detto agent advertisement (contiene care-of-address)
 - host risponde con una registration request, che viene girata alla home agent (gli manda il nuovo care-of-address).
 - home agent risponde con registration reply, che arriva al host.


Nelle reti mobile IP la home network corrisponde alla rete del provider a cui siamo iscritti.
Il provider possiede un Home Location Register (HLR), un database con <numero telefono, informazioni, posizione attuale>
Possiede anche un Visitor Location Register (VLR), database identico a HLR ma riguardante solo gli utenti che in qul momento stanno usando la rete (sarà utile per la visited network).


Iniziamo dalla GSM, rete cellulare usata per le chiamate telefoniche.
 - Corrispondente inizia una chiamata verso un utente mobile, viene mandata alla home network.
 - Mobile switching center (MSC) della home network consulta HLR, troviamo dove si trova utente.
 - Rotuing indiretto, MSC attiva una seconda chiamata alla MSC della visited network.
 - MSC visited completa la chiamata facendola passare da base station fino all'utente.
Cap 6 slide 62 per chiarezza.


Tecnica handoff: se utente si sposta e resta sotto la stessa MSC ma si avvicina ad un'altra BS allora inoltra chiamta sulla nuova BS.
Motivi: segnale migliore, redistribuzione del carico. Funziona così:
 - vecchia BS informa MSC del handoff.
 - MSC prepara il percorso.
 - nuova BS alloca canale radio per nuovo utente.
 - nuova BS dice a MSC di informare vecchia BS che è pronta.
 - mobile passa a nuova BS e informa MSC del cambio effettuato con successo.


E se utente dovesse allontanarsi e passare ad una nuova MSC?
 => MSC vecchia farà da ancora per la nuova MSC, catena di MSC!
 => ci possono essere degli handoff tra MSC per diminuire la catena.


Un commento sulla mobilità per quanto riguarda i livelli della pila internet:
Tutto è stato progettato in modo da non dover cambiare i vecchi livelli e l'impatto sia minimo, ma dal punto di vista delle performance ovviamente avremo dei problemi:
 - perdita di pacchetti e delay, sopratutto durante gli handoff
 - TCP quando vede perdita di pacchetti pensa alla congestione => inutile diminuzione della finestra di invio.
 - purtroppo le reti wireless non sono ottime come quelle wired in termini di velocità e errori.